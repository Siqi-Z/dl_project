{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from Preprocess import load_captions\n",
    "from data_loader import DataLoader\n",
    "from data_loader import get_loader \n",
    "from Vocabulary import Vocabulary\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public_directory = 'COCO'\n",
    "local_directory = 'test'\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize smoothing function\n",
    "smoothing = SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = 'models/encoder-1-200.ckpt'\n",
    "decoder_path = 'models/decoder-1-200.ckpt'\n",
    "\n",
    "vocab_path = 'train'\n",
    "image_dir = local_directory\n",
    "\n",
    "# caption_path = public_directory+'/annotations/captions_train2014.json'\n",
    "\n",
    "embed_size = 512\n",
    "hidden_size = 4096\n",
    "num_layers = 1\n",
    "crop_size = 224\n",
    "\n",
    "log_step = 50\n",
    "batch_size = 1\n",
    "num_workers = 2\n",
    "\n",
    "threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = load_captions(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions_dict['2513260012_03d33305cf.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(captions_dict, threshold)\n",
    "vocab_size = vocab.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "# image = transform(Image.open(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 512\n",
    "# vocab_size = vocab.index\n",
    "# hidden_dim = 512\n",
    "# model_name = model\n",
    "# cnn = get_cnn(architecture = model_name, embedding_dim = embedding_dim)\n",
    "# lstm = RNN(embedding_dim = embedding_dim, hidden_dim = hidden_dim, vocab_size = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(image_dir, vocab, transform)\n",
    "imagenumbers, captiontotal, imagetotal= dataloader.gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(imagenumbers, captiontotal, imagetotal, batch_size,\n",
    "                         shuffle=True, num_workers=num_workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Model:  resnet152\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderCNN(embed_size).eval()  # eval mode (batchnorm uses moving mean/variance)\n",
    "encoder = encoder.to(device)\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embed): Embedding(1809, 512)\n",
      "  (lstm): LSTM(512, 4096, batch_first=True)\n",
      "  (linear): Linear(in_features=4096, out_features=1809, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "decoder = decoder.to(device)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model parameters\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "decoder.load_state_dict(torch.load(decoder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(data_loader)\n",
    "\n",
    "# List to score the BLEU scores\n",
    "bleu_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.3834  \n",
      "---------------------------------------------------\n",
      "Target:  <start> two men <unk> a sign that says `` <unk> or <unk> `` . <end>\n",
      "Output:  <start> a man in a red shirt and a <unk> <unk> <unk> . <end>\n",
      "\n",
      "\n",
      "Finish [0/5000], Current BLEU Score: 0.3834\n",
      "---------------------------------------------------\n",
      "\n",
      "1:0.3894  2:0.2022  3:0.4167  4:0.3583  5:0.2388  6:0.3894  7:0.4167  8:0.2007  9:0.0556  10:0.3033  11:0.2500  12:0.2577  13:0.5000  14:0.3333  15:0.2500  16:0.2500  17:0.1298  18:0.3791  19:0.3033  20:0.2747  21:0.1667  22:0.0985  23:0.4232  24:0.5000  25:0.1580  26:0.2921  27:0.4167  28:0.1765  29:0.2500  30:0.2527  31:0.2000  32:0.3527  33:0.2500  34:0.3834  35:0.3527  36:0.1667  37:0.2084  38:0.3333  39:0.4600  40:0.2084  41:0.1667  42:0.3436  43:0.2022  44:0.1667  45:0.5000  46:0.1623  47:0.3846  48:0.3583  49:0.3583  50:0.1667  \n",
      "---------------------------------------------------\n",
      "Target:  <start> the two children swinging together on a swing . <end>\n",
      "Output:  <start> a man in a red shirt and a <unk> <unk> <unk> . <end>\n",
      "\n",
      "\n",
      "Finish [50/5000], Current BLEU Score: 0.2890\n",
      "---------------------------------------------------\n",
      "\n",
      "51:0.2500  52:0.3333  53:0.2605  54:0.3333  55:0.3067  56:0.3333  57:0.3067  58:0.6250  59:0.1433  60:0.4167  61:0.3333  62:0.2500  63:0.2921  64:0.1667  65:0.2388  66:0.3033  67:0.3333  68:0.5367  69:0.4383  70:0.1667  71:0.3333  72:0.2500  73:0.2500  74:0.4777  75:0.4167  76:0.2362  77:0.4167  78:0.2084  79:0.3333  80:0.4545  81:0.2353  82:0.1338  83:0.2577  84:0.3333  85:0.5516  86:0.3333  87:0.3333  88:0.3750  89:0.5000  90:0.2139  91:0.1667  92:0.2388  93:0.4000  94:0.5000  95:0.2362  96:0.2500  97:0.2173  98:0.2500  99:0.2941  100:0.3851  \n",
      "---------------------------------------------------\n",
      "Target:  <start> a <unk> , holding <unk> in her hand , and wearing a <unk> <unk> , looks in a <unk> . <end>\n",
      "Output:  <start> a man in a red shirt and a <unk> <unk> <unk> . <end>\n",
      "\n",
      "\n",
      "Finish [100/5000], Current BLEU Score: 0.3039\n",
      "---------------------------------------------------\n",
      "\n",
      "101:0.1667  102:0.2500  103:0.2336  104:0.5000  105:0.1667  106:0.2535  107:0.4167  108:0.3033  109:0.3436  110:0.4167  111:0.2921  112:0.1667  113:0.2778  114:0.3198  115:0.2577  116:0.1623  117:0.2362  118:0.0625  119:0.2116  120:0.1433  121:0.4395  122:0.1516  123:0.3345  124:0.3333  125:0.2778  126:0.0833  127:0.5643  128:0.3067  129:0.1667  130:0.4167  131:0.0859  132:0.2362  133:0.1516  134:0.2822  135:0.6250  136:0.1176  137:0.3583  138:0.2300  139:0.3750  140:0.2500  141:0.3033  142:0.2500  143:0.6250  144:0.2500  145:0.3543  146:0.4167  147:0.3333  148:0.1667  149:0.5000  150:0.3889  \n",
      "---------------------------------------------------\n",
      "Target:  <start> a group of people are <unk> a boat in a <unk> . <end>\n",
      "Output:  <start> a man in a red shirt and a black and white <unk> is <unk> a <unk> <unk> . <end>\n",
      "\n",
      "\n",
      "Finish [150/5000], Current BLEU Score: 0.2996\n",
      "---------------------------------------------------\n",
      "\n",
      "151:0.4167  152:0.2021  153:0.4868  154:0.1667  155:0.3333  156:0.2500  157:0.0590  158:0.1338  159:0.4167  160:0.1765  161:0.6349  162:0.1429  163:0.5000  164:0.2567  165:0.1765  166:0.2921  167:0.2500  168:0.3333  169:0.2362  170:0.4180  171:0.4868  172:0.2500  173:0.2353  174:0.3333  175:0.1111  176:0.2500  177:0.3309  178:0.1181  179:0.2897  180:0.2500  181:0.5155  182:0.2197  183:0.2500  184:0.2921  185:0.3834  186:0.1667  187:0.2596  188:0.5000  189:0.4167  190:0.3333  191:0.0000  192:0.1217  193:0.2500  194:0.2362  195:0.2995  196:0.6250  197:0.2332  198:0.2300  199:0.5000  200:0.1074  \n",
      "---------------------------------------------------\n",
      "Target:  <start> an orange dog and a little white dog with black <unk> are next to a white car . <end>\n",
      "Output:  <start> a dog is running through the water . <end>\n",
      "\n",
      "\n",
      "Finish [200/5000], Current BLEU Score: 0.2971\n",
      "---------------------------------------------------\n",
      "\n",
      "201:0.2676  202:0.2500  203:0.4296  204:0.3834  205:0.4296  206:0.3527  207:0.5841  208:0.1947  209:0.2747  210:0.4545  211:0.6250  212:0.2388  213:0.3894  214:0.2000  215:0.2353  216:0.4543  217:0.2941  218:0.1264  219:0.4543  220:0.2500  221:0.2500  222:0.2921  223:0.2197  224:0.0833  225:0.1765  226:0.3894  227:0.4167  228:0.5000  229:0.3529  230:0.1667  231:0.0812  232:0.3245  233:0.1667  234:0.2500  235:0.1563  236:0.6000  237:0.1718  238:0.1533  239:0.4167  240:0.0000  241:0.1667  242:0.3333  243:0.5833  244:0.4412  245:0.0833  246:0.5000  247:0.4286  248:0.1765  249:0.3033  250:0.2952  \n",
      "---------------------------------------------------\n",
      "Target:  <start> a dog is splashing through water trying to catch ice in its mouth . <end>\n",
      "Output:  <start> a dog is running through the grass . <end>\n",
      "\n",
      "\n",
      "Finish [250/5000], Current BLEU Score: 0.2992\n",
      "---------------------------------------------------\n",
      "\n",
      "251:0.4167  252:0.2274  253:0.3834  254:0.4868  255:0.4600  256:0.1667  257:0.3245  258:0.1667  259:0.4180  260:0.2300  261:0.3436  262:0.5307  263:0.3333  264:0.2500  265:0.2747  266:0.2388  267:0.2500  268:0.3345  269:0.1765  270:0.4296  271:0.1667  272:0.4395  273:0.3333  274:0.2007  275:0.1667  276:0.2921  277:0.3255  278:0.4938  279:0.1718  280:0.2500  281:0.3255  282:0.4167  283:0.2274  284:0.3333  285:0.3750  286:0.0833  287:0.3834  288:0.1667  289:0.3245  290:0.5516  291:0.5643  292:0.2941  293:0.1667  294:0.3333  295:0.1667  296:0.2500  297:0.5000  298:0.1516  299:0.1667  300:0.5841  \n",
      "---------------------------------------------------\n",
      "Target:  <start> white <unk> <unk> dog is running through the ocean . <end>\n",
      "Output:  <start> a dog is running through the grass . <end>\n",
      "\n",
      "\n",
      "Finish [300/5000], Current BLEU Score: 0.3015\n",
      "---------------------------------------------------\n",
      "\n",
      "301:0.5000  302:0.2941  303:0.3345  304:0.2921  305:0.4868  306:0.2500  307:0.3333  308:0.2274  309:0.1563  310:0.3583  311:0.4133  312:0.3309  313:0.4167  314:0.4543  315:0.2500  316:0.3345  317:0.2500  318:0.1667  319:0.3333  320:0.6619  321:0.5000  322:0.4167  323:0.1380  324:0.3750  325:0.5833  326:0.2857  327:0.1563  328:0.3894  329:0.3750  330:0.1176  331:0.2500  332:0.4167  333:0.3750  334:0.2116  335:0.2577  336:0.4167  337:0.4549  338:0.1302  339:0.2500  340:0.2941  341:0.1181  342:0.4868  343:0.1667  344:0.3345  345:0.3894  346:0.4167  347:0.6619  348:0.1765  349:0.2500  350:0.6619  \n",
      "---------------------------------------------------\n",
      "Target:  <start> the dog is running with a colorful ball . <end>\n",
      "Output:  <start> a dog is running through the grass . <end>\n",
      "\n",
      "\n",
      "Finish [350/5000], Current BLEU Score: 0.3067\n",
      "---------------------------------------------------\n",
      "\n",
      "351:0.3333  352:0.4167  353:0.4232  354:0.2676  355:0.1667  356:0.2362  357:0.4549  358:0.4167  359:0.2219  360:0.3296  361:0.2500  362:0.2921  363:0.4938  364:0.1667  365:0.3309  366:0.3333  367:0.2500  368:0.4118  369:0.3296  370:0.4395  371:0.1667  372:0.4868  373:0.1066  374:0.3527  375:0.5000  376:0.1074  377:0.2790  378:0.1250  379:0.2921  380:0.3333  381:0.5000  382:0.4044  383:0.0856  384:0.2778  385:0.0833  386:0.4167  387:0.5000  388:0.3527  389:0.3333  390:0.0833  391:0.0833  392:0.2116  393:0.1533  394:0.1947  395:0.4938  396:0.3000  397:0.1765  398:0.2500  399:0.1533  400:0.3333  \n",
      "---------------------------------------------------\n",
      "Target:  <start> football players <unk> to <unk> something to <unk> <unk> . <end>\n",
      "Output:  <start> a man in a red shirt and a <unk> <unk> <unk> . <end>\n",
      "\n",
      "\n",
      "Finish [400/5000], Current BLEU Score: 0.3051\n",
      "---------------------------------------------------\n",
      "\n",
      "401:0.3750  402:0.1667  403:0.1103  404:0.0000  405:0.1250  406:0.1667  407:0.3245  408:0.1718  409:0.1042  410:0.3333  411:0.4167  412:0.2500  413:0.5000  414:0.2139  415:0.1395  416:0.2206  417:0.4118  418:0.4600  419:0.2986  420:0.1667  421:0.4600  422:0.1667  423:0.2727  424:0.2921  425:0.1667  426:0.3846  427:0.4296  428:0.4706  429:0.5833  430:0.2022  431:0.1811  432:0.1667  433:0.2500  434:0.2500  435:0.0859  436:0.4600  437:0.0833  438:0.5000  439:0.2941  440:0.3436  441:0.3720  442:0.1711  443:0.0833  444:0.2435  445:0.4938  446:0.2676  447:0.3333  448:0.2500  449:0.3309  450:0.2577  \n",
      "---------------------------------------------------\n",
      "Target:  <start> two wet , black dogs are running through some sand . <end>\n",
      "Output:  <start> a dog is running through the grass . <end>\n",
      "\n",
      "\n",
      "Finish [450/5000], Current BLEU Score: 0.3019\n",
      "---------------------------------------------------\n",
      "\n",
      "451:0.2300  452:0.3704  453:0.2197  454:0.5000  455:0.2084  456:0.3894  457:0.1875  458:0.2197  459:0.2778  460:0.4180  461:0.2500  462:0.3333  463:0.1111  464:0.1947  465:0.2007  466:0.2500  467:0.2500  468:0.1839  469:0.3894  470:0.2778  471:0.2921  472:0.4296  473:0.3333  474:0.3309  475:0.3750  476:0.4549  477:0.2577  478:0.5000  479:0.2007  480:0.1947  481:0.0833  482:0.1563  483:0.2921  484:0.1947  485:0.1667  486:0.3149  487:0.3333  488:0.6134  489:0.2822  490:0.2577  491:0.3583  492:0.1667  493:0.2388  494:0.0588  495:0.4167  496:0.2500  497:0.4167  498:0.3333  499:0.2577  500:0.0000  \n",
      "---------------------------------------------------\n",
      "Target:  <start> three dogs racing on racetrack <end>\n",
      "Output:  <start> a dog is running through the water . <end>\n",
      "\n",
      "\n",
      "Finish [500/5000], Current BLEU Score: 0.2997\n",
      "---------------------------------------------------\n",
      "\n",
      "501:0.2941  502:0.5000  503:0.2941  504:0.5000  505:0.2500  506:0.2500  507:0.3333  508:0.1667  509:0.3333  510:0.4167  511:0.2500  512:0.5000  513:0.1667  514:0.1667  515:0.4868  516:0.1580  517:0.1765  518:0.4167  519:0.3033  520:0.1947  521:0.0833  522:0.4167  523:0.3333  524:0.3894  525:0.3750  526:0.0833  527:0.3333  528:0.5000  529:0.1264  530:0.3325  531:0.2300  532:0.4167  533:0.1116  534:0.3333  535:0.1563  536:0.3538  537:0.5000  538:0.3333  539:0.1667  540:0.3333  541:0.3894  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e23193709d9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Generate an caption from the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0msampled_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0msampled_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampled_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\DL_Project_Flickr_2\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;34m\"\"\"Extract feature vectors from input images.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 301\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "        \n",
    "    # Set mini-batch dataset\n",
    "    images = images.to(device)\n",
    "    # captions = captions.to(device)\n",
    "    \n",
    "    # print(images.shape)\n",
    "    # torch.Size([256, 3, 224, 224])\n",
    "    # torch.Size([256, 2048, 1, 1])\n",
    "    # torch.Size([256, 2048])\n",
    "    # torch.Size([256, 256])\n",
    "\n",
    "    # Generate an caption from the image\n",
    "    feature = encoder(images)\n",
    "    sampled_ids = decoder.sample(feature)\n",
    "    sampled_ids = sampled_ids[0].cpu().numpy()\n",
    "\n",
    "    # Convert word_ids to words\n",
    "    sampled_caption = []\n",
    "    for word_id in sampled_ids:\n",
    "        word = vocab.id2word[word_id]\n",
    "        sampled_caption.append(word)\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    output = ' '.join(sampled_caption)\n",
    "    \n",
    "    # Convert target word_ids to words\n",
    "    captions = captions[0].cpu().numpy()\n",
    "    target_caption = []\n",
    "    for word_id in captions:\n",
    "        word = vocab.id2word[word_id]\n",
    "        target_caption.append(word)\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    target = ' '.join(target_caption)\n",
    "    \n",
    "    # Convert string to a list and ignore <start> <end>\n",
    "    target_list = target.split()[1:-1]\n",
    "    output_list = output.split()[1:-1]\n",
    "\n",
    "    score = sentence_bleu([target_list], \n",
    "                           output_list, \n",
    "                          weights=(1, 0, 0, 0),\n",
    "                           smoothing_function=smoothing.method3)\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "    print('{}:{:.4f}  '.format(i, score), end=\"\")\n",
    "    \n",
    "    # Print log info\n",
    "    if i % log_step == 0:\n",
    "        print('\\n---------------------------------------------------')\n",
    "        print('Target: ', target)\n",
    "        print('Output: ', output)\n",
    "        print('\\n')\n",
    "        print('Finish [{}/{}], Current BLEU Score: {:.4f}'\n",
    "              .format(i, total_step, np.mean(bleu_scores)))\n",
    "        print('---------------------------------------------------\\n')\n",
    "\n",
    "np.save(\"tests.npy\", [bleu_scores, np.mean(bleu_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-22279b945b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mids_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_out = cnn(image)\n",
    "ids_list = lstm.greedy(cnn_out)\n",
    "\n",
    "plt.imshow(Image.open(i))\n",
    "plt.show()\n",
    "print(vocab.get_sentence(ids_list))\n",
    "\n",
    "batch_bleu_4 += sentence_bleu([caption_word_list], \n",
    "                              predicted_word_list,\n",
    "                              smoothing_function=smoothing.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5562862736224321"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([target_list], \n",
    "                           output_list, \n",
    "                          weights=(1, 0, 0, 0),\n",
    "                           smoothing_function=smoothing.method7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siqiz4\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\siqiz4\\AppData\\Local\\Continuum\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38940039153570244"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([target_list], \n",
    "                           output_list, \n",
    "                          weights=(1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
