{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "from Preprocess import load_captions\n",
    "from data_loader import DataLoader\n",
    "from data_loader import get_loader \n",
    "from Vocabulary import Vocabulary\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "train_dir=\"./train\"\n",
    "\n",
    "model_path = 'models/'\n",
    "\n",
    "crop_size = 224\n",
    "lr = 1e-3\n",
    "num_epochs = 80\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "hidden_size = 512\n",
    "embed_size = 512\n",
    "num_layers = 1\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "log_step = 100\n",
    "save_step = 200\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = load_captions(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(captions_dict, threshold)\n",
    "vocab_size = vocab.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dir, vocab, transform)\n",
    "imagenumbers, captiontotal, imagetotal= dataloader.gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(imagenumbers, captiontotal, imagetotal, batch_size,\n",
    "                         shuffle=True, num_workers=num_workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(embed_size).to(device)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train step [100/235], Loss: 2.9047, Perplexity: 18.2600, Time:  1.25 min\n",
      "Epoch 1, Train step [200/235], Loss: 2.6438, Perplexity: 14.0660, Time:  2.40 min\n",
      "Epoch 1, Train step [235/235], Loss: 2.5773, Perplexity: 13.1622, Time:  2.79 min\n",
      "Epoch 2, Train step [100/235], Loss: 2.4499, Perplexity: 11.5866, Time:  4.00 min\n",
      "Epoch 2, Train step [200/235], Loss: 2.3458, Perplexity: 10.4421, Time:  5.14 min\n",
      "Epoch 2, Train step [235/235], Loss: 2.3343, Perplexity: 10.3226, Time:  5.54 min\n",
      "Epoch 3, Train step [100/235], Loss: 2.1136, Perplexity:  8.2777, Time:  6.74 min\n",
      "Epoch 3, Train step [200/235], Loss: 2.2255, Perplexity:  9.2585, Time:  7.90 min\n",
      "Epoch 3, Train step [235/235], Loss: 2.1556, Perplexity:  8.6334, Time:  8.29 min\n",
      "Epoch 4, Train step [100/235], Loss: 2.0653, Perplexity:  7.8874, Time:  9.43 min\n",
      "Epoch 4, Train step [200/235], Loss: 2.0168, Perplexity:  7.5140, Time: 10.51 min\n",
      "Epoch 4, Train step [235/235], Loss: 2.1403, Perplexity:  8.5019, Time: 10.90 min\n",
      "Epoch 5, Train step [100/235], Loss: 1.9938, Perplexity:  7.3433, Time: 12.11 min\n",
      "Epoch 5, Train step [200/235], Loss: 1.9544, Perplexity:  7.0600, Time: 13.26 min\n",
      "Epoch 5, Train step [235/235], Loss: 1.9254, Perplexity:  6.8576, Time: 13.65 min\n",
      "Epoch 6, Train step [100/235], Loss: 1.8346, Perplexity:  6.2624, Time: 14.86 min\n",
      "Epoch 6, Train step [200/235], Loss: 1.9794, Perplexity:  7.2381, Time: 16.00 min\n",
      "Epoch 6, Train step [235/235], Loss: 1.9116, Perplexity:  6.7638, Time: 16.40 min\n",
      "Epoch 7, Train step [100/235], Loss: 1.7494, Perplexity:  5.7513, Time: 17.60 min\n",
      "Epoch 7, Train step [200/235], Loss: 1.8164, Perplexity:  6.1494, Time: 18.71 min\n",
      "Epoch 7, Train step [235/235], Loss: 1.7224, Perplexity:  5.5977, Time: 19.06 min\n",
      "Epoch 8, Train step [100/235], Loss: 1.6642, Perplexity:  5.2817, Time: 20.13 min\n",
      "Epoch 8, Train step [200/235], Loss: 1.7194, Perplexity:  5.5810, Time: 21.28 min\n",
      "Epoch 8, Train step [235/235], Loss: 1.7432, Perplexity:  5.7154, Time: 21.68 min\n",
      "Epoch 9, Train step [100/235], Loss: 1.5052, Perplexity:  4.5051, Time: 22.89 min\n",
      "Epoch 9, Train step [200/235], Loss: 1.6141, Perplexity:  5.0233, Time: 24.01 min\n",
      "Epoch 9, Train step [235/235], Loss: 1.5382, Perplexity:  4.6561, Time: 24.35 min\n",
      "Epoch 10, Train step [100/235], Loss: 1.5625, Perplexity:  4.7706, Time: 25.45 min\n",
      "Epoch 10, Train step [200/235], Loss: 1.5627, Perplexity:  4.7718, Time: 26.47 min\n",
      "Epoch 10, Train step [235/235], Loss: 1.5209, Perplexity:  4.5765, Time: 26.82 min\n"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "start_train_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Train\n",
    "    for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "\n",
    "        # Set mini-batch dataset\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "\n",
    "        # Forward, backward and optimize\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get training statistics\n",
    "        stats = \"Epoch {:0>2d}, Train step [{:0>3d}/{}], Loss: {:.4f}, Perplexity: {:>7.4f}, Time: {:>6.2f} min\".\\\n",
    "        format(epoch+1, i+1, total_step, loss.item(), np.exp(loss.item()), (time.time() - start_train_time)/60)\n",
    "        # Print training statistics (on same line)\n",
    "        print(\"\\r\" + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training stats (on different line), reset time and save checkpoint\n",
    "        if (i+1) % log_step == 0:\n",
    "            print(\"\\r\" + stats)\n",
    "\n",
    "        # Save the model checkpoints\n",
    "        if (i+1) % save_step == 0:\n",
    "            torch.save(decoder.state_dict(), os.path.join(\n",
    "                model_path, 'decoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "            torch.save(encoder.state_dict(), os.path.join(\n",
    "                model_path, 'encoder-{}-{}.ckpt'.format(epoch+1, i+1)))\n",
    "    print()\n",
    "    \n",
    "    # Test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embed): Embedding(1072, 512)\n",
      "  (lstm): LSTM(512, 512, batch_first=True)\n",
      "  (linear): Linear(in_features=512, out_features=1072, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
